{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabio\\miniconda3\\envs\\LOB\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "import json\n",
    "#from sklearn.metrics import brier_score_loss, log_loss, accuracy_score, precision_score, recall_score, f1_score\n",
    "from torchcp.classification.scores import THR, APS, SAPS, RAPS\n",
    "from torchcp.classification.predictors import ClassWisePredictor\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Callable, Optional\n",
    "from model.DeepLOB import deeplob\n",
    "from utils.torch_dfs import LobDataset\n",
    "from utils.constants import DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration Data Shape: torch.Size([44482, 1, 100, 40]) torch.Size([44482])\n",
      "Validation Data Shape: torch.Size([6270, 1, 100, 40]) torch.Size([6270])\n",
      "Test Data Shape: torch.Size([139488, 1, 100, 40]) torch.Size([139488])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "\n",
    "dec_data = np.loadtxt('data/input/Train_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "\n",
    "dec_cal = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):int(np.floor(dec_data.shape[1] * 0.975))]\n",
    "dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.975)):]\n",
    "\n",
    "dataset_cal = LobDataset(data=dec_cal, k=4, num_classes=3, T=100)\n",
    "cal_loader = torch.utils.data.DataLoader(dataset=dataset_cal, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print('Calibration Data Shape:', dataset_cal.x.shape, dataset_cal.y.shape)\n",
    "\n",
    "dataset_val = LobDataset(data=dec_val, k=4, num_classes=3, T=100)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print('Validation Data Shape:', dataset_val.x.shape, dataset_val.y.shape)\n",
    "\n",
    "del dec_cal, dec_data, dataset_cal, dec_val, dataset_val\n",
    "\n",
    "dec_test1 = np.loadtxt('data/input/Test_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "dec_test2 = np.loadtxt('data/input/Test_Dst_NoAuction_DecPre_CF_8.txt')\n",
    "dec_test3 = np.loadtxt('data/input/Test_Dst_NoAuction_DecPre_CF_9.txt')\n",
    "dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
    "\n",
    "dataset_test = LobDataset(data=dec_test, k=4, num_classes=3, T=100)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "print('Test Data Shape:',dataset_test.x.shape, dataset_test.y.shape)\n",
    "\n",
    "del dec_test, dec_test1, dec_test2, dec_test3, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_27420\\3860720545.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(model_path,  map_location=torch.device(DEVICE))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deeplob(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 2), stride=(1, 2))\n",
       "    (1): Tanh()\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): Tanh()\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): Tanh()\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 32, kernel_size=(1, 10), stride=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(4, 1), stride=(1, 1))\n",
       "    (7): LeakyReLU(negative_slope=0.01)\n",
       "    (8): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp1): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp2): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=same)\n",
       "    (4): LeakyReLU(negative_slope=0.01)\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (inp3): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), dilation=1, ceil_mode=False)\n",
       "    (1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), padding=same)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (lstm): LSTM(192, 64, batch_first=True)\n",
       "  (fc1): Linear(in_features=64, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = deeplob(y_len = 3)\n",
    "model_path = 'model/best_val_model_pytorch'\n",
    "\n",
    "model = torch.load(model_path,  map_location=torch.device(DEVICE))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APS\n",
      "Processing alpha: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 2.08325: 100%|██████████| 50/50 [02:39<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.1, best temperature: 0.10314480661523805, test results: {'Coverage_rate': 0.9232693851800872, 'Average_size': 1.9881065037852719, 'Unilable_share': 0.21719431062170222, 'Multiclass_brier_score': 0.159585007991448, 'Log_loss': 2.0040067345260324}\n",
      "Processing alpha: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 1.73333: 100%|██████████| 50/50 [02:43<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.15, best temperature: 0.1000532615330806, test results: {'Coverage_rate': 0.8864059990823583, 'Average_size': 1.6252795939435651, 'Unilable_share': 0.5100295365909612, 'Multiclass_brier_score': 0.15974838608490413, 'Log_loss': 2.06510884878605}\n",
      "Processing alpha: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 22. Best value: 1.44992: 100%|██████████| 50/50 [02:41<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.2, best temperature: 0.10139253489752549, test results: {'Coverage_rate': 0.8490049323239275, 'Average_size': 1.3386958017894013, 'Unilable_share': 0.772647109428768, 'Multiclass_brier_score': 0.15967801944402102, 'Log_loss': 2.038176686377976}\n",
      "Processing alpha: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 27. Best value: 1.24705: 100%|██████████| 50/50 [02:38<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.25, best temperature: 0.24595228876761777, test results: {'Coverage_rate': 0.8111307065840789, 'Average_size': 1.1792268869006652, 'Unilable_share': 0.8416566299610002, 'Multiclass_brier_score': 0.14588861072847134, 'Log_loss': 0.9014917152774021}\n",
      "RAPS\n",
      "Processing alpha: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 2.09171: 100%|██████████| 50/50 [03:13<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.1, best lambda: 0.008357896885019755, best temperature: 0.10380197281502251, test results: {'Coverage_rate': 0.9225238013305804, 'Average_size': 2.0092552764395504, 'Unilable_share': 0.14810593025923377, 'Multiclass_brier_score': 0.15954984097586802, 'Log_loss': 1.9914924146790354}\n",
      "Processing alpha: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 43. Best value: 1.76794: 100%|██████████| 50/50 [03:35<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.15, best lambda: 0.13171775971443256, best temperature: 0.10162370423079647, test results: {'Coverage_rate': 0.8859256710254646, 'Average_size': 1.6724664487267722, 'Unilable_share': 0.39444253269098417, 'Multiclass_brier_score': 0.15966581090655696, 'Log_loss': 2.033600574184409}\n",
      "Processing alpha: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 1.47352: 100%|██████████| 50/50 [03:30<00:00,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.2, best lambda: 0.3902138725982041, best temperature: 0.10345045315413344, test results: {'Coverage_rate': 0.8516001376462491, 'Average_size': 1.4057840100940582, 'Unilable_share': 0.596983253039688, 'Multiclass_brier_score': 0.15956867113686402, 'Log_loss': 1.9981663368526796}\n",
      "Processing alpha: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 1.22584: 100%|██████████| 50/50 [04:42<00:00,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.25, best lambda: 0.004431951570958215, best temperature: 0.10699858367086625, test results: {'Coverage_rate': 0.8139051387933012, 'Average_size': 1.1700576393668272, 'Unilable_share': 0.8401439550355586, 'Multiclass_brier_score': 0.15937644705640513, 'Log_loss': 1.9328382520089356}\n",
      "SAPS\n",
      "Processing alpha: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: 1.94147: 100%|██████████| 50/50 [03:31<00:00,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.1, best lambda: 0.0009767558715134683, best temperature: 1.1350458718068384, test results: {'Coverage_rate': 0.916745526496903, 'Average_size': 1.6930847097958248, 'Unilable_share': 0.6216520417526956, 'Multiclass_brier_score': 0.1541455999388238, 'Log_loss': 0.8152895107195505}\n",
      "Processing alpha: 0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 37. Best value: 1.70032: 100%|██████████| 50/50 [03:40<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.15, best lambda: 0.0029230963279330228, best temperature: 0.2374245697739303, test results: {'Coverage_rate': 0.8842409382885983, 'Average_size': 1.5060220233998625, 'Unilable_share': 0.7180044161504933, 'Multiclass_brier_score': 0.14699863964203286, 'Log_loss': 0.9259502925630406}\n",
      "Processing alpha: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 16. Best value: 1.47352: 100%|██████████| 50/50 [03:34<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.2, best lambda: 0.0020929906442391406, best temperature: 9.45517426213012, test results: {'Coverage_rate': 0.8481518123422803, 'Average_size': 1.3412551617343427, 'Unilable_share': 0.7996243404450563, 'Multiclass_brier_score': 0.21254572201642, 'Log_loss': 1.0557639572640254}\n",
      "Processing alpha: 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 41. Best value: 1.25837: 100%|██████████| 50/50 [03:36<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.25, best lambda: 0.1418194793019299, best temperature: 0.6642571908511493, test results: {'Coverage_rate': 0.8139983367744895, 'Average_size': 1.2061539343886212, 'Unilable_share': 0.8341506079376003, 'Multiclass_brier_score': 0.13133892735748606, 'Log_loss': 0.7174870526066658}\n",
      "Results saved to results_minsetsize.json\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.1, 0.15, 0.2, 0.25]\n",
    "score_fun = [APS, RAPS, SAPS]\n",
    "res = {}\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def evaluate_predictor(fun: Callable, alpha: float, temperature: float, x: Optional[float] = None, loader=None):\n",
    "    if loader is None:\n",
    "        loader = val_loader  # Default to validation loader if none provided\n",
    "\n",
    "    if x is not None:\n",
    "        predictor = ClassWisePredictor(score_function=fun(x), model=model, temperature=temperature)\n",
    "    else:\n",
    "        predictor = ClassWisePredictor(score_function=fun(), model=model, temperature=temperature)\n",
    "    \n",
    "    predictor.calibrate(cal_loader, alpha)\n",
    "    return predictor.evaluate(loader)\n",
    "\n",
    "def objective(trial, fun: Callable, alpha: float):\n",
    "    temperature = trial.suggest_float(\"temperature\", 0.1, 10.0, log=True)\n",
    "    \n",
    "    if fun not in [APS]:\n",
    "        x = trial.suggest_float(\"lambda\", 0, 1)\n",
    "        evaluation_results = evaluate_predictor(fun, alpha, temperature, x)\n",
    "    else:\n",
    "        evaluation_results = evaluate_predictor(fun, alpha, temperature)\n",
    "    \n",
    "    coverage_rate = evaluation_results['Coverage_rate']\n",
    "    average_size = evaluation_results['Average_size']\n",
    "    unilable_share = evaluation_results['Unilable_share']\n",
    "    \n",
    "    brier_score = evaluation_results['Multiclass_brier_score']\n",
    "    log_loss = evaluation_results['Log_loss']\n",
    "    \n",
    "    if coverage_rate >= 1 - alpha:\n",
    "        return average_size  # Direction is minimize so adjust sign accordingly\n",
    "    else:\n",
    "        return float('inf')  # Penalize trials that don't meet the coverage rate requirement\n",
    "\n",
    "def process_score_function(fun: Callable):\n",
    "    fun_name = fun.__name__\n",
    "    print(fun_name)\n",
    "    res[fun_name] = {}\n",
    "    \n",
    "    for alpha in alphas:\n",
    "        print(f'Processing alpha: {alpha}')\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        study.optimize(lambda trial: objective(trial, fun, alpha), n_trials=50, show_progress_bar=True)\n",
    "        \n",
    "        best_temperature = study.best_params['temperature']\n",
    "        if fun not in [APS]:\n",
    "            best_lambda = study.best_params['lambda']\n",
    "            # After finding the best hyperparameters, evaluate on the test set\n",
    "            evaluation_results = evaluate_predictor(fun, alpha, best_temperature, best_lambda, loader=test_loader)\n",
    "            res[fun_name][str(alpha)] = {\n",
    "                \"best_lambda\": best_lambda,\n",
    "                \"best_temperature\": best_temperature,\n",
    "                \"test_results\": evaluation_results\n",
    "            }\n",
    "            print(f'alpha: {alpha}, best lambda: {best_lambda}, best temperature: {best_temperature}, test results: {evaluation_results}')\n",
    "        else:\n",
    "            # For APS, only tune temperature\n",
    "            evaluation_results = evaluate_predictor(fun, alpha, best_temperature, loader=test_loader)\n",
    "            res[fun_name][str(alpha)] = {\n",
    "                \"best_temperature\": best_temperature,\n",
    "                \"test_results\": evaluation_results\n",
    "            }\n",
    "            print(f'alpha: {alpha}, best temperature: {best_temperature}, test results: {evaluation_results}')\n",
    "\n",
    "for fun in score_fun:\n",
    "    process_score_function(fun)\n",
    "\n",
    "with open('results_minsetsize.json', 'w') as json_file:\n",
    "    json.dump(res, json_file, indent=4)\n",
    "\n",
    "print(\"Results saved to results_minsetsize.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
